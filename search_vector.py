import os
import argparse
from nltk_downloader import NLTKDataDownloader
from data_processor import DataProcessor
from vector_retrieval import VectorRetrieval


def ensure_documents(data_path: str, cache_dir: str, max_files: int, use_cache_only: bool):
    dp = DataProcessor(data_path=data_path, max_files=max_files, cache_dir=cache_dir)
    # å°è¯•ä»ç¼“å­˜åŠ è½½
    if dp.load_documents_from_cache():
        return dp.get_documents()

    if use_cache_only:
        print('âŒ æœªæ‰¾åˆ°æ–‡æ¡£ç¼“å­˜ï¼Œä¸”å¯ç”¨äº† --use_cache_only')
        return {}

    print('âš ï¸  æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå°è¯•è§£ææ•°æ®ä»¥ä¾›å‘é‡æ£€ç´¢ä½¿ç”¨...')
    dp.parse_event_files(use_cache=True)
    return dp.get_documents()


def main():
    parser = argparse.ArgumentParser(description='å‘é‡æ£€ç´¢ï¼ˆåŸºäºä¼˜åŒ– TF-IDFï¼‰')
    parser.add_argument('--data_path', type=str, default='Meetup/All_Unpack', help='æ•°æ®è·¯å¾„ï¼ˆç”¨äºåŠ è½½/ç”Ÿæˆç¼“å­˜çš„æ–‡æ¡£ï¼‰')
    parser.add_argument('--cache_dir', type=str, default='Meetup/cache', help='ç¼“å­˜ç›®å½•')
    parser.add_argument('--max_files', type=int, default=10000, help='æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆä¸æ„å»ºæ—¶ä¿æŒä¸€è‡´ï¼Œ0 ä¸ºå…¨éƒ¨ï¼‰')
    parser.add_argument('--top_k', type=int, default=10, help='è¿”å›å‰Kä¸ªæ–‡æ¡£')
    parser.add_argument('--max_features', type=int, default=30000, help='TF-IDF è¯æ±‡è¡¨å¤§å°ä¸Šé™')
    parser.add_argument('--query', type=str, default=None, help='æŸ¥è¯¢è¯­å¥ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰')
    parser.add_argument('--use_cache_only', action='store_true', help='ä»…ä½¿ç”¨ç¼“å­˜çš„æ–‡æ¡£ï¼Œä¸é‡æ–°è§£æ')
    args = parser.parse_args()

    if not os.path.exists(args.data_path):
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {args.data_path}")
        return 1

    # å‡†å¤‡ NLTKï¼ˆå¯é€‰ï¼‰
    try:
        NLTKDataDownloader.download_required_data()
    except Exception:
        pass

    max_files = args.max_files if args.max_files > 0 else None
    documents = ensure_documents(args.data_path, args.cache_dir, max_files, args.use_cache_only)
    if not documents:
        print('âŒ æ— æ³•åŠ è½½æ–‡æ¡£ï¼Œé€€å‡º')
        return 2

    vr = VectorRetrieval(documents, cache_dir=args.cache_dir)

    def do_query(q: str):
        results, cost = vr.search(q, top_k=args.top_k, use_cache=True, max_features=args.max_features)
        print(f"ğŸ” æŸ¥è¯¢: {q}")
        print(f"â±ï¸  è€—æ—¶: {cost:.4f}s  |  è¿”å›: {len(results)} æ¡")
        for i, (doc_id, score) in enumerate(results, 1):
            name = documents[doc_id]['name']
            if len(name) > 50:
                name = name[:50] + '...'
            print(f"  {i}. [ç›¸ä¼¼åº¦: {score:.4f}] [{doc_id}] {name}")

    if args.query:
        do_query(args.query)
        return 0

    print('=== å‘é‡æ£€ç´¢ (äº¤äº’æ¨¡å¼) ===')
    print("è¾“å…¥æŸ¥è¯¢ï¼Œæˆ–è¾“å…¥ 'exit' é€€å‡º")
    while True:
        try:
            q = input('query> ').strip()
        except (EOFError, KeyboardInterrupt):
            print('\nå†è§!')
            break
        if not q or q.lower() in {'exit', 'quit', ':q'}:
            break
        do_query(q)

    return 0


if __name__ == '__main__':
    raise SystemExit(main())
